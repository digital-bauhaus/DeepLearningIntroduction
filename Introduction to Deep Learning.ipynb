{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "  # <center>Introduction to Deep Learning</center>\n",
    "## <center>by André Karge 2018</center>\n",
    "\n",
    "<center><img src=\"./logo_withName_klein.png\"></center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>1. What is Deep Learning?</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Machine Learning approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Deep Learning = Artificial Neural Network (ANN)\n",
    "- in general: learning of data representations by applying linear algebra magic\n",
    "- have a look at the [wiki page](https://en.wikipedia.org/wiki/Deep_learning) of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "+ many fields for application\n",
    "    - image recognition\n",
    "    - natural language processing\n",
    "    - bioinformatics\n",
    "    - and many more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- first version of an ANN: perceptron [Rosenblatt, 1958]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> 1.1 Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Developed in 1958 by Frank Rosenblatt\n",
    "- have a look at the [wiki](https://en.wikipedia.org/wiki/Perceptron) page\n",
    "<center><img src=\"http://www.rutherfordjournal.org/images/TAHC_rosenblatt-sepia.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "image source: [http://www.rutherfordjournal.org/images/TAHC_rosenblatt-sepia.jpg](http://www.rutherfordjournal.org/images/TAHC_rosenblatt-sepia.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- is a simplified neural network to model the processes of neurons in our brain\n",
    "- perceptron definition by Tom Mitchell<sub>[T. Mitchell. Machine Learning. McGraw-Hill Book Co, 1997]</sub>:\n",
    "\n",
    "> a perceptron is a unit which takes a vector $\\vec{x}$ of real valued inputs of size n ($\\vec{x} = x_1, x_2, ..., x_n$); calculates a linear combination of these inputs and outputs a 1 if the result is greater than some threshold and -1 otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- mathematically:\n",
    "$$\n",
    "\\begin{align}\n",
    "    o(x_1, ..., x_n) = \\begin{cases}\n",
    "        \\,\\;\\;1&if\\;w_0 + w_1x_1 +w_2x_2 + ... + w_nx_n > 0\\\\\n",
    "        -1&otherwise\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- $w_i$ is a weight which controls the contribution of input $x_i$ to the output $o(\\vec{x})$ of the perceptron\n",
    "> **Note**: to simplify the equation, we can add a constant $x_0=1$, which allows us to express the equation aboth as: $\\vec{w}*\\vec{x} > 0$:\n",
    "$$\n",
    "\\begin{align}\n",
    "    o(x_1, ..., x_n) = \\begin{cases}\n",
    "        \\,\\;\\;1&if\\;\\vec{w}*\\vec{x} > 0\\\\\n",
    "        -1&otherwise\n",
    "    \\end{cases}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the application of the threshold is called **activation function**\n",
    "+ it controls output of perceptron with a function\n",
    "    - here: a step function\n",
    "    - later: a more advanced function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### visualization of a perceptron:\n",
    "![image of a perceptron](perceptron-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- in order to learn with a perceptron: we have to find appropriate values for $\\vec{w}=w_0, w_1, ..., w_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- this means: the space of $H$ of all candidate hypotheses for the weight vector $\\vec{w}$ is the set of all possible real-valued weight vectors:\n",
    "> $H = \\{\\vec{w}\\;|\\;\\vec{w} \\in {\\rm I\\!R}^{(n+1)}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- the usage of a perceptron creates a hyperplane through the $n$-dimensional space of instances which classifies points on each side of it as $1$ or $-1$\n",
    "- if a set of examples can be classified that way it is called a **linear separable set of examples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img alt=\"perceptron hyperspace\" width=500 src=\"./perceptron_hyperspace.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- But: there exist sets which are not linear separable (for example the XOR operator):\n",
    "<center><img alt=\"XOR hyperspace\" src=\"./XOR.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center> 1.2 Multi-Layer-Perceptron</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the problem of the non-separability can be solved by using **multi-layered perceptrons**\n",
    "- also: the weights can be adjusted by the application of the **backpropagation algorithm** ([wiki](https://en.wikipedia.org/wiki/Backpropagation), [example](http://www.offconvex.org/2016/12/20/backprop/))\n",
    "- multi-layer perceptron = multiple perceptrons stacked together to form a meshed network:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img alt=\"multilayer_perceptron\" src=\"MultiLayerPerceptron-1.png\" height=800, width=700></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- multi-layer perceptron consists of at least 3 layers: one input layer, $n\\geq1$ hidden layers, one output layer\n",
    "- each layer consists of a set of perceptrons (also called **neurons**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Input Layer**\n",
    "- consists of $i$ neurons where $i$ denotes the dimension of the input parameter\n",
    "- the input neurons only forward their feeded value because they don't have any activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Hidden Layer**\n",
    "- consist of $h$ neurons where $h$ denotes the dimension of the layer\n",
    "- there can be an arbitary number of hidden layers\n",
    "- called hidden because they are not visible to an external user of the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Output Layer**\n",
    "- consist of $o$ neurons where $o$ denotes the desired output dimension (e.g.: the number of classes)\n",
    "- output neurons produce a signal in form of a value or a vector which has to be interpreted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Each connection between two neurons models a weighted information pass\n",
    "> Note: The key concept is to adjust the weights of the meshed network during the training process\n",
    "- an additional bias for a neuron controls its sensitivity and with what value it starts to give an output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Forward Pass\n",
    "<center><img alt=\"weights\" src=\"WeightsBiases-1.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "This is what happens in all linear layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$$\n",
    "\\begin{align}\n",
    "        % \\vec{y} = activation(W \\cdot \\vec{x} + \\vec{b})\n",
    "        \\begin{bmatrix}\n",
    "            y_1\\\\\n",
    "            y_2\n",
    "        \\end{bmatrix}\n",
    "        =\n",
    "        activation(W \\cdot \\vec{x} + \\vec{b})\n",
    "        =\n",
    "        activation\\left(\n",
    "            \\begin{bmatrix}\n",
    "                w_{11} & w_{21}\\\\\n",
    "                w_{12} & w_{22}\n",
    "            \\end{bmatrix}\n",
    "            \\cdot\n",
    "            \\begin{bmatrix}\n",
    "                x_1\\\\\n",
    "                x_2\n",
    "            \\end{bmatrix}\n",
    "            +\n",
    "            \\begin{bmatrix}\n",
    "                b_1\\\\\n",
    "                b_2\n",
    "            \\end{bmatrix}\n",
    "        \\right)\n",
    "    \\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The major difference between a multi-layer perceptron to classical perceptrons is that it doesn't use a step function for activation\n",
    "+ now we use activation functions which are continuously differentiable so that we can apply the backpropagation algorithm e.g.:\n",
    "    - sigmoidal function\n",
    "    > $sig(t) = \\frac{1}{1 + e^t}$ <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png\" width=200>\n",
    "    - tanh function\n",
    "    > $tanh(t) = \\frac{e^t - e^{-t}}{e^t + e^{-t}}\\$ <img src=\"https://upload.wikimedia.org/wikipedia/commons/8/87/Hyperbolic_Tangent.svg\" width=200>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "image sources:\n",
    "- sig: [ttps://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png](ttps://upload.wikimedia.org/wikipedia/commons/thumb/8/88/Logistic-curve.svg/320px-Logistic-curve.svg.png)\n",
    "- tanh: [https://upload.wikimedia.org/wikipedia/commons/8/87/Hyperbolic_Tangent.svg](https://upload.wikimedia.org/wikipedia/commons/8/87/Hyperbolic_Tangent.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Running Example Multi-Layer Perceptron in Pytorch (XOR)\n",
    "- we know: $a\\;xor\\;b = (a \\vee b) \\wedge \\neg(a \\wedge b)$\n",
    "- so we need in general 3 neurons: logical *and*, logical *or* and a logical *and* for the output of the first neurons\n",
    "- input is 2-dimensional: $x$=[$x_1$, $x_2$]\n",
    "- output is 1-dimensional: $y$=[$y_1$]\n",
    "- remember: the input layer by default is just an interface which forwards the inputs to the hidden layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "based on the tutorial here: [link](https://courses.cs.washington.edu/courses/cse446/18wi/sections/section8/XOR-Pytorch.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img alt=\"xor_network\" src=\"xor_network.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "what you need to run this script:\n",
    "- pytorch: pip install torch | conda install pytorch torchvision -c pytorch\n",
    "- numpy: pip install numpy | conda install -c conda-forge numpy\n",
    "- matplotlib: pip install matplotlib | conda install -c conda-forge matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Lets build our training data\n",
    "X = torch.Tensor([[0,0],[0,1],[1,0],[1,1]])\n",
    "Y = torch.Tensor([0,1,1,0]).view(-1,1) # transpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class XOR(nn.Module):\n",
    "    def __init__(self, input_dim=2, output_dim=1):\n",
    "        super(XOR, self).__init__()\n",
    "        self.lin1 = nn.Linear(input_dim, 2) # 2 neurons for input (learns and + or)\n",
    "        self.lin2 = nn.Linear(2, output_dim) # 1 neuron for output (learns XOR based on given and + or results)\n",
    "    def forward(self, x):\n",
    "        x = self.lin1(x)\n",
    "        x = torch.sigmoid(x) # apply activation function\n",
    "        x = self.lin2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "model = XOR()\n",
    "def init_weights(model):\n",
    "    for m in model.modules():\n",
    "        if isinstance(m, nn.Linear):\n",
    "            # inititalize the weights for all modules in the given model with random normal\n",
    "            m.weight.data.normal_(-1, 1)\n",
    "init_weights(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss() # mean squared error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9) # stochastic gradient descent optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 loss: 1.6779945\n",
      "step: 100 loss: 0.11734449\n",
      "step: 200 loss: 0.24371906\n",
      "step: 300 loss: 0.101343125\n",
      "step: 400 loss: 0.042008523\n",
      "step: 500 loss: 0.0004923791\n",
      "step: 600 loss: 0.00010126142\n",
      "step: 700 loss: 7.748078e-10\n",
      "step: 800 loss: 9.979573e-10\n",
      "step: 900 loss: 6.089209e-10\n",
      "step: 1000 loss: 1.5010215e-11\n",
      "step: 1100 loss: 1.4210855e-12\n",
      "step: 1200 loss: 1.2789769e-13\n",
      "step: 1300 loss: 5.684342e-14\n",
      "step: 1400 loss: 3.1974423e-14\n",
      "step: 1500 loss: 3.5527137e-15\n",
      "step: 1600 loss: 5.1159077e-13\n",
      "step: 1700 loss: 6.004086e-13\n",
      "step: 1800 loss: 7.993606e-13\n",
      "step: 1900 loss: 5.684342e-14\n",
      "step: 2000 loss: 5.1159077e-13\n",
      "step: 2100 loss: 1.4210855e-12\n",
      "step: 2200 loss: 4.2987836e-13\n",
      "step: 2300 loss: 5.1159077e-13\n",
      "step: 2400 loss: 5.1159077e-13\n",
      "step: 2500 loss: 7.993606e-13\n",
      "step: 2600 loss: 1.0267343e-12\n",
      "step: 2700 loss: 9.094947e-13\n",
      "step: 2800 loss: 9.094947e-13\n",
      "step: 2900 loss: 1.7408297e-13\n",
      "step: 3000 loss: 7.993606e-13\n",
      "step: 3100 loss: 1.2789769e-13\n",
      "step: 3200 loss: 5.684342e-14\n",
      "step: 3300 loss: 4.2987836e-13\n",
      "step: 3400 loss: 5.1159077e-13\n",
      "step: 3500 loss: 8.881784e-14\n",
      "step: 3600 loss: 6.963319e-13\n",
      "step: 3700 loss: 7.993606e-13\n",
      "step: 3800 loss: 1.0267343e-12\n",
      "step: 3900 loss: 3.5527137e-13\n",
      "step: 4000 loss: 3.5527137e-15\n",
      "step: 4100 loss: 2.877698e-13\n",
      "step: 4200 loss: 5.684342e-14\n",
      "step: 4300 loss: 8.881784e-14\n",
      "step: 4400 loss: 1.2789769e-13\n",
      "step: 4500 loss: 7.993606e-13\n",
      "step: 4600 loss: 1.4210855e-14\n",
      "step: 4700 loss: 6.004086e-13\n",
      "step: 4800 loss: 2.2737368e-13\n",
      "step: 4900 loss: 0.0\n",
      "step: 5000 loss: 4.2987836e-13\n",
      "step: 5100 loss: 4.2987836e-13\n",
      "step: 5200 loss: 4.2987836e-13\n",
      "step: 5300 loss: 1.4210855e-14\n",
      "step: 5400 loss: 6.004086e-13\n",
      "step: 5500 loss: 1.4210855e-14\n",
      "step: 5600 loss: 2.877698e-13\n",
      "step: 5700 loss: 9.094947e-13\n",
      "step: 5800 loss: 3.5527137e-13\n",
      "step: 5900 loss: 2.877698e-13\n",
      "step: 6000 loss: 6.004086e-13\n",
      "step: 6100 loss: 2.877698e-13\n",
      "step: 6200 loss: 6.963319e-13\n",
      "step: 6300 loss: 3.1974423e-14\n",
      "step: 6400 loss: 6.963319e-13\n",
      "step: 6500 loss: 8.881784e-14\n",
      "step: 6600 loss: 3.5527137e-13\n",
      "step: 6700 loss: 1.7408297e-13\n",
      "step: 6800 loss: 4.2987836e-13\n",
      "step: 6900 loss: 5.684342e-14\n",
      "step: 7000 loss: 3.5527137e-15\n",
      "step: 7100 loss: 1.0267343e-12\n",
      "step: 7200 loss: 1.4210855e-14\n",
      "step: 7300 loss: 3.1974423e-14\n",
      "step: 7400 loss: 3.1974423e-14\n",
      "step: 7500 loss: 3.5527137e-15\n",
      "step: 7600 loss: 1.2789769e-13\n",
      "step: 7700 loss: 1.0267343e-12\n",
      "step: 7800 loss: 5.684342e-14\n",
      "step: 7900 loss: 2.877698e-13\n",
      "step: 8000 loss: 2.877698e-13\n",
      "step: 8100 loss: 3.5527137e-15\n",
      "step: 8200 loss: 1.7408297e-13\n",
      "step: 8300 loss: 1.4210855e-14\n",
      "step: 8400 loss: 1.7408297e-13\n",
      "step: 8500 loss: 3.5527137e-13\n",
      "step: 8600 loss: 3.5527137e-13\n",
      "step: 8700 loss: 2.877698e-13\n",
      "step: 8800 loss: 3.5527137e-15\n",
      "step: 8900 loss: 1.2789769e-13\n",
      "step: 9000 loss: 1.7408297e-13\n",
      "step: 9100 loss: 8.881784e-14\n",
      "step: 9200 loss: 5.1159077e-13\n",
      "step: 9300 loss: 6.963319e-13\n",
      "step: 9400 loss: 2.877698e-13\n",
      "step: 9500 loss: 2.2737368e-13\n",
      "step: 9600 loss: 3.1974423e-14\n",
      "step: 9700 loss: 2.2737368e-13\n",
      "step: 9800 loss: 2.877698e-13\n",
      "step: 9900 loss: 0.0\n"
     ]
    }
   ],
   "source": [
    "epochs = 10000\n",
    "steps = X.size(0)\n",
    "all_losses = []\n",
    "for e in range(epochs):\n",
    "    for i in range(steps):\n",
    "        data_point = np.random.randint(X.size(0)) # choose random data point\n",
    "        x_var = Variable(X[data_point], requires_grad=False) # doesn't require to be a learnable variable\n",
    "        y_var = Variable(Y[data_point], requires_grad=False) # doesn't require to be a learnable variable\n",
    "        \n",
    "        optimizer.zero_grad() # reset the current gradient\n",
    "        y_ = model(x_var) # prediction\n",
    "        loss = loss_function.forward(y_, y_var) # get the loss\n",
    "        loss.backward() # backpopagate\n",
    "        optimizer.step() # application of new weights\n",
    "        all_losses.append(loss.detach().numpy())\n",
    "    if e % 100 == 0:\n",
    "        print(\"step:\", e, \"loss:\", loss.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 xor 1 = 0\n"
     ]
    }
   ],
   "source": [
    "#testinput = [0,0]\n",
    "#testinput = [0,1]\n",
    "#testinput = [1,0]\n",
    "testinput = [1,1]\n",
    "test = model(Variable(torch.Tensor(testinput), requires_grad=False))\n",
    "print(\"{} xor {} = {}\".format(testinput[0], testinput[1], int(np.round(test.detach().numpy())[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now we learned an XOR operator with Deep Learning :D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <center>2. Networks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- the network which was shown in the last chapter was a **fully-connected network**\n",
    "- each neuron of a layer is connected with each neuron of the next layer\n",
    "+ there exist different networks topologies, such as:\n",
    "    - convolutional neural networks\n",
    "    - recurrent neural networks\n",
    "    - recursive neural networks\n",
    "    - sequence to sequence networks\n",
    "    - autoencoder\n",
    "    - ...\n",
    "- each network type can be applied to different fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### <center>2.1 Recurrent Neural Networks (RNNs)</center>\n",
    "- a neural network for learning timed series\n",
    "- what does timed series mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a timed series can be: sensor measurements, stock market values, ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- but can also be: sequences such as text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "RNN Unit:\n",
    "<center><img src=\"RNN-0.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- $x$ is our input sequence\n",
    "- $y$ is our ouptut sequence\n",
    "- in the middle is our network which has two outputs: one for y and another one which is passed back in the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- but how can we learn text with this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"RNN.png\" width=800></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- we unfold the network\n",
    "- $x = [x_1, x_2, x_3, ..., x_t]$\n",
    "- $y = [y_1, y_2, y_3, ..., y_t]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a property of the RNN is that the hidden node shares its information across the network (since it is a single neuron)\n",
    "- the input is passed into the neuron step by step, starting with $x_1$ and; further, a hidden state $h_0$ which represents some kind of knowledge about the previous sequence elements\n",
    "> at each time step $t : t \\in \\mathbb{N}^n$ the next prediction $y_t$ depends on $x_t$ and $h_{t-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- there are different topologies for RNNs:\n",
    "<center><img src=\"https://discuss.pytorch.org/uploads/default/original/1X/6415da0424dd66f2f5b134709b92baa59e604c55.jpg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "image source: [https://discuss.pytorch.org/uploads/default/original/1X/6415da0424dd66f2f5b134709b92baa59e604c55.jpg](https://discuss.pytorch.org/uploads/default/original/1X/6415da0424dd66f2f5b134709b92baa59e604c55.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "+ examples:\n",
    "    - one-to-one: feed-forward\n",
    "    - one-to-many: generate music based on a given value which encodes genere of music\n",
    "    - many-to-one: generate the next word in a given text sequence or classify the given sequence\n",
    "    - many-to-many: generate a response for a given chat message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- a big weakness of vanilla RNNs is the so called **vanishing gradient problem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- when the network becomes bigger and bigger $\\rightarrow$ becomes harder for backpropagation to affect the weights of the first nodes:\n",
    "> The influence of the element at $t_{i-j}\\;|\\;j \\in \\mathbb{N}^{n > 0}$ the influence of the error becomes smaller the greater $j$ becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> example sentence: \"*The game which I had as a child and played with my friends and ... was removed last year*\"\n",
    "\n",
    "- remembering that *game* was written in singular is hard for the vanilla RNN due to the vanishing gradient problem so it doesn't know anymore that a correct prediction would be \"*was removed last year*\" vs \"*were removed last year*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Solution: a new cell type called **Long Short Term Memory** (LSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>2.2 Long Short Term Memory (LSTM)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- an LSMT unit is a kind of an RNN unit, designed to solve the vanishing gradient problem\n",
    "- developed by Sepp Hochreiter & Jürgen Schmidhuber [1997]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "+ vanilla RNN:\n",
    "    - information pass = gate $\\Gamma$\n",
    "+ LSTM Cell consist of memory cells and different gates:\n",
    "    - forget gate $\\Gamma_f$\n",
    "    - update gate $\\Gamma_u$\n",
    "    - output gate $\\Gamma_o$\n",
    "- each gate has its own weights $W$ and $U$ and biases $b$ which are adjusted during training\n",
    "- all gates use a sigmoid activation $\\sigma$ in order to apply backpropagation\n",
    "- $\\rightarrow$ enables the LSTM cell to learn when to remember and forget certain information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<center><img src=\"LSTM-1.png\" width=800></center>\n",
    "\n",
    "- $c_t$ is the hidden state memory\n",
    "- $a_t$ is the hidden state activation (equivalent to hidden state in classic RNNs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"LSTM-1.png\" width=500>\n",
    "This is what happens in the cell mathematically:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "    \\Gamma_f =&\\; \\sigma(W_f[a_{t-1}, x_t] + U_f[a_{t-1}, x_t] + b_f)\\\\\n",
    "    \\Gamma_u =&\\; \\sigma(W_u[a_{t-1}, x_t] + U_u[a_{t-1}, x_t] + b_u)\\\\\n",
    "    \\Gamma_o =&\\; \\sigma(W_o[a_{t-1}, x_t] + U_o[a_{t-1}, x_t] + b_o)\\\\\n",
    "    % \\Gamma_o =&\\; \\sigma(W_o[a_{t-1}, x_t] + b_o)}\\\\\n",
    "    c^n_t =&\\; tanh(W_c[a_{t-1}, x_t] + U_c[a_{t-1}, x_t] + b_c)\\\\\n",
    "    c_t =&\\; \\Gamma_u \\cdot c^n_t + \\Gamma_f \\cdot c_{t-1}\\\\\n",
    "    a_t =&\\; \\Gamma_o \\cdot tanh(c_t)\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- another type for an inproved RNN-Cell is the Gated-Recurrent-Unit (GRU)\n",
    "- wiki: [link](https://en.wikipedia.org/wiki/Gated_recurrent_unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Pytorch Example for an RNN: [link](https://pytorch.org/tutorials/beginner/nlp/sequence_models_tutorial.html#sphx-glr-beginner-nlp-sequence-models-tutorial-py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>2.3 Data for RNNs</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Standard example is this text:\n",
    "> \"*The quick brown fox jumps over the lazy dog*\"\n",
    "> <img src=\"https://i.imgur.com/VT0Nd.gif\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "gif source: [https://imgur.com/gallery/VT0Nd](https://imgur.com/gallery/VT0Nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> which sequences can you detect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- character sequence: \"T\", \"h\", \"e\", \" \", \"q\", ...\n",
    "- n-gram sequence on characters: \"Th\", \"he\", \"h \", \" q\", \"qu\", ...\n",
    "- word sequence: \"The\", \"quick\", \"brown\", ...\n",
    "- n-gram sequence on words: \"The quick\", \"quick brown\", \"brown fox\", ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- choosing the appropriate sequence scheme is called **Language Model** in Natual Language Processing (NLP)\n",
    "> A Language Model is a probability distribution over a sequence of timed series\n",
    "- this could be a character, a word or word pairs for text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In order to learn a recurrent network: we have to tokenize the input sequence first\n",
    "- In the rest of this introduction we suppose that we work with text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- a neural network learns probabilities over sequences of numbers and predicts some number or some sequence of numbers\n",
    "- how to express text as numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- easy: use a dictionary with an index mapping!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- lets say we use a character level language model and our text\n",
    "> *The quick brown fox jumps over the lazy dog*\n",
    "\n",
    "- we would tokenize the text so that each character is one element in the sequence\n",
    "> how large is our vocabulary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- right: 26 with only lower-case characters and 52 combined with upper-case characters + special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "alphabet = ['a','b','c','d','e','f','g','h','i','j','k','l','m',\n",
    "            'n','o','p','q','r','s','t','u','v','w','x','y','z',\n",
    "            'A','B','C','D','E','F','G','H','I','J','K','L','M',\n",
    "            'N','O','P','Q','R','S','T','U','V','W','X','Y','Z']\n",
    "# add whitespace\n",
    "alphabet = alphabet + [' ']\n",
    "char2index = {}\n",
    "index2char = {}\n",
    "for index, char in enumerate(alphabet):\n",
    "    char2index[char] = index\n",
    "    index2char[index] = char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "print(char2index['j'])\n",
    "print(index2char[15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45, 7, 4, 52, 16, 20, 8, 2, 10, 52, 1, 17, 14, 22, 13, 52, 5, 14, 23, 52, 9, 20, 12, 15, 18, 52, 14, 21, 4, 17, 52, 19, 7, 4, 52, 11, 0, 25, 24, 52, 3, 14, 6]\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog\"\n",
    "tokens = []\n",
    "for char in sentence:\n",
    "    tokens.append(char2index[char])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox jumps over the lazy dog\n"
     ]
    }
   ],
   "source": [
    "translated_sentence = \"\"\n",
    "for index in tokens:\n",
    "    translated_sentence += index2char[index]\n",
    "print(translated_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> What if we chose a word level language model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- how many words are there in the english language?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- right: too many\n",
    "- this is why we have to shrinken our vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Method**:\n",
    "- usage of k-most-frequent words or words above a threshold in our training text\n",
    "- $\\rightarrow$ read your complete training data, tokenize it after your selected scheme and count the occurencies\n",
    "- afterwards: remove those words from your vocabulary which occur less than the given threshold or only use the k-most-frequent words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> what if we encounter a word while tokenization which is not in the vocabulary?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- simple: use a special token for that: \"*< UNK >*\" or \"*< OoV >*\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Embeddings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- now we have a sequence of indices\n",
    "- to insert this in the network, we have to build an appropriate neural network input in the form of vectors\n",
    "- the vectorization of Words is called **Word Embedding**\n",
    "- the most naive way would be to use **one-hot encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "why one-hot? [link](https://machinelearningmastery.com/why-one-hot-encode-data-in-machine-learning/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- means: for each element in the sequence we build a vector of the size of the vocabulary\n",
    "- this vector contains zeros except a 1 at the position of the index of the element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "vectorized = []\n",
    "for index in tokens:\n",
    "    vector = np.zeros(len(alphabet))\n",
    "    vector[index] = 1\n",
    "    vectorized.append(vector)\n",
    "print(vectorized[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This kind of embedding consumes much memory and is very sparse\n",
    "- That's why nobody uses the naive variant\n",
    "- We can embed words even more efficiently"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In 2013, Google Research developed an improved embedding approach called **Word2Vec**\n",
    "- It is possible to embed words with their context as part of speech in a dense vector representation\n",
    "- This Embedding uses the **distributional hypothesis** which assumes that words which appear in similar context are also related to each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- no more large sparse zero vectors and some context encoding!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "+ Word2Vec provides two architectures:\n",
    "    + Continuous Bag of Words (CBoW)\n",
    "        - encoding of a word based on its surrounding context\n",
    "    + Continuous skip-gram\n",
    "        - encoding of surrounding context based on a word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Example CBoW**\n",
    "> sentence = [\"The\",\"quick\",\"brown\",\"fox\",\"jumps\",\"over\",\"the\",\"lazy\",\"dog\"]<br>\n",
    "> cbow = [[\"The\", \"quick\", \"fox\", \"jumps\"], \"brown\"]\n",
    "\n",
    "- \"brown\" has the context \"The\", \"quick\", \"fox\" and \"jumps\" in the example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- So we have to train word2vec embeddings beforehand\n",
    "- afterwards, we can embed our words into this trained dense vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- words with similar meaning are close to each other in this dense vector space\n",
    "- we can even do arithmetics on the vectors\n",
    "<img src=\"CBOW-1.png\" width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "$v_{king} - v_{man} + v_{woman} \\approx v_{queen}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>2.4 Seq2Seq</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Sequence to Sequence (Seq2Seq) is a special kind of an RNN\n",
    "- basically consist of 2 Modules:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*3i6BEx7G2tyuGzgR4NZ62w@2x.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "image source: [https://cdn-images-1.medium.com/max/800/1*3i6BEx7G2tyuGzgR4NZ62w@2x.png](https://cdn-images-1.medium.com/max/800/1*3i6BEx7G2tyuGzgR4NZ62w@2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- last encoder state is passed to decoder as its first state\n",
    "- note that the input of the decoder is $\\hat{y}_{t-1}$ (ground truth) and not $y_{t-1}$ (the generated output of the last step)\n",
    "- $\\rightarrow$ the decoder in this image is for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the encoder *encodes* the input sequence into a dense vector representation (the last hidden state)\n",
    "- it is basically an LSTM layer (but can also be a bi-directional LSTM or GRU)\n",
    "- last hidden state is passed to the decoder which uses this representation to build a sequence which is most probably the best response to the input sequence\n",
    "- also: this is another LSTM layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- the initial hidden state of the encoder normally is a zero vector (but can also be something else to encode some pre-knowledge)\n",
    "- the initial hidden state of the decoder is the last hidden state of the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the decoder must have two modes: training and inference\n",
    "+ training: on each time step the input is the given ground truth ($x_t^{decoder} \\leftarrow \\hat{y}_{t-1}$)\n",
    "    - this prevents the network from passing errors through the decoder\n",
    "    - example: if the first generated word is wrong and used as input for the next time step $\\rightarrow$ all other predictions are based on the first wrong generation $\\rightarrow$ makes training hard\n",
    "+ inference: on each time step the result of the last time step is used as input ($x_t^{decoder} \\leftarrow y_{t-1}$)\n",
    "    - since in final application, we don't know what the ground truth is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inference Decoder:\n",
    "<center><img src=\"https://cdn-images-1.medium.com/max/800/1*_6-EVV3RJXD5KDjdnxztzg@2x.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "image source: [https://cdn-images-1.medium.com/max/800/1*_6-EVV3RJXD5KDjdnxztzg@2x.png](https://cdn-images-1.medium.com/max/800/1*_6-EVV3RJXD5KDjdnxztzg@2x.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Improvements for Seq2Seq**\n",
    "- Attention ([Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473))\n",
    "- Pointer Networks ([Pointer Networks](http://papers.nips.cc/paper/5866-pointer-networks))\n",
    "- Copy Mechanic ([Incorporating Copying Mechanism in Sequence-to-Sequence Learning](https://arxiv.org/abs/1603.06393))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Tutorial for Seq2Seq with Attention using pytorch: [link](https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>3. Some Other Networks</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Convolutional Neural Networks (CNNs)**\n",
    "- a neural network for learning convolution\n",
    "- in general: it learns convolution kernels over data\n",
    "- application fields are mostly image analysis and audio processing, but can also be applied to other fields such as text analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "image source: [https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png](https://upload.wikimedia.org/wikipedia/commons/6/63/Typical_cnn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "example for a CNN in pytorch: [link](https://blog.algorithmia.com/convolutional-neural-nets-in-pytorch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Recursive Neural Networks**\n",
    "- be careful: are also abbreviated with RNN\n",
    "- but are different to recurrent networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"https://image.slidesharecdn.com/rnn-parsing-151230182007/95/parsing-natural-scenes-and-natural-language-with-recursive-neural-networks-3-638.jpg?cb=1453938346\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "image source : [https://image.slidesharecdn.com/rnn-parsing-151230182007/95/parsing-natural-scenes-and-natural-language-with-recursive-neural-networks-3-638.jpg?cb=1453938346](https://image.slidesharecdn.com/rnn-parsing-151230182007/95/parsing-natural-scenes-and-natural-language-with-recursive-neural-networks-3-638.jpg?cb=1453938346)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- recursive neural networks make use of hierarchical structure of data and try to encode it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "papers for recursive networks:\n",
    "- [Parsing Natural Scenes and Natural Language with Recursive Neural Networks](https://nlp.stanford.edu/pubs/SocherLinNgManning_ICML2011.pdf)\n",
    "- [Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks](https://arxiv.org/abs/1503.00075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### <center>4. Deep Learning for Source Code Generation</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Have the following Java snippet:\n",
    "```java\n",
    "public class SampleClass {\n",
    "    int add() {\n",
    "\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> how could a neural network learn such structure?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- in text form as it is $\\rightarrow$ give this text to an RNN and predict next tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- or: use the hierarchical structure of code and learn that by using the **Abstract Syntax Tree** (AST) of the source code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Abstract Syntax Tree is the abstract representation of a program in tree format\n",
    "- every source code can be translated into its AST since each programming language consists of a context free grammar with finite set of commands & rules\n",
    "- normally: format is used by compilers, debuggers, validators\n",
    "- advantages: we don't have to learn punctuation or default structures (after an *if* comes a bracket followed by a logical expression which is followed by a closing bracket and a code block)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- this is the AST of the source code which we saw before:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"Sample_AST_CompilationUnit-1.png\" width=500></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"Sample_AST_CompilationUnit-1.png\" width=200>\n",
    "\n",
    "+ we can see: it constists of 2 types of nodes:\n",
    "    + <span style=\"color:blue\">blue</span> = non-terminal node\n",
    "        - every non-leaf node\n",
    "        - corresponds to a non-terminal element of the context free grammar\n",
    "        - are language specific elements such as: *ExpressionStatement*, *CompilationUnit*, ...\n",
    "    + <span style=\"color:green\">green</span> = terminal node\n",
    "        - every leaf node\n",
    "        - corresponds to terminal elements of the context free grammar\n",
    "        - such as: *identifiers*, *strings*, *number-literals*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- the structure follows a defined scheme\n",
    "- each non-terminal node can have only a specific set of child node types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- terminal nodes represent identifiers, strings and so on $\\rightarrow$ there are infinite variations of nodes possible\n",
    "- but: for the program structure we have a defined set of possible non-terminal nodes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- we can either give the AST to a *recursive* neural network or serialize it and give it to a *recurrent* neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center><img src=\"tree.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- from here on the rest depends on the preprocessing (creation of a tree and feed it to a network or using some tree serialization tool to flatten the tree as a sequence)\n",
    "- It depends on what you want to do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Thats it for our \"short\" introduction into Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "oblicatory cat picture\n",
    "<img src=\"http://www.cutenessoverflow.com/wp-content/uploads/2015/05/cat-tongue-out-22.jpg\" width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "image source: [http://www.cutenessoverflow.com/wp-content/uploads/2015/05/cat-tongue-out-22.jpg](http://www.cutenessoverflow.com/wp-content/uploads/2015/05/cat-tongue-out-22.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Any Questions?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Links**\n",
    "- [coursera deep learning course](https://www.coursera.org/learn/neural-networks-deep-learning)\n",
    "- [coursera sequence models course](https://www.coursera.org/learn/nlp-sequence-models)\n",
    "- [udacity deep learning course](https://eu.udacity.com/course/deep-learning-nanodegree--nd101)\n",
    "- [pytorch tutorials](https://pytorch.org/tutorials/)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
